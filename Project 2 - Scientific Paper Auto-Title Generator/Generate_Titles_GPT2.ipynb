{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "587f2195-0a96-4f79-bd24-6347281bba92",
   "metadata": {},
   "source": [
    "# Scientific Paper Title Generator Using GPT-2 \n",
    "\n",
    "The following Notebook outlines the steps required to perform a title generation specific to a body of text. \\\n",
    "In the case below, we will be walking through how to produce an AI generated Title based on Scientific research texts scraped from ArXiv - a popular scientific community forum housing an enormous number of research texts\n",
    "\n",
    "Key Project Objectives:\n",
    "- Data will be scraped from the Open-Access [ArXiv.org Platform](https://arxiv.org/)\n",
    "- Text data will be fed to the GPT-2 Model in order to fine-tune the selected model\n",
    "- Titles will be generated after Fine-tuning is completed\n",
    "\n",
    "Source Information:\n",
    "1) [ArXiv.org](https://arxiv.org/)\n",
    "2) [GPT-2 by HuggingFace](https://huggingface.co/gpt2)\n",
    "3) [ArXiv Scraper Library](https://github.com/Mahdisadjadi/arxivscraper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c9135-0996-41af-b805-b37431d881f2",
   "metadata": {},
   "source": [
    "# 1. Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da9b13-fff3-4fc1-b5de-a87c712912bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Requirements file from Dependencies used in Current Environment\n",
    "!pip list > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a99be-8c84-4abd-b3c6-13bf670a3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries to be used\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arxivscraper as ax\n",
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e905a8e-58d9-485b-b6fd-2d9798bbe953",
   "metadata": {},
   "source": [
    "# 2. Scrape & Retrieve Raw Data from ArXiv\n",
    "\n",
    "Let's look at physics as the main type of research paper as ArXiv has a vast number of those in its database\n",
    "\n",
    "These are specified through the scraper with the `category` tag:\n",
    " - `physics` -- subcategory: Quantum Physics/Mechanics `quant-ph`\n",
    " \n",
    " Let's also explore recent Information from the last 1-2 years\n",
    " \n",
    " A Limitation of using this library however is that the scraper can only target one specific Field at a time. Therefore, we have to scrape 1 group at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ae870-b2ea-4970-9b06-9c3ebcb76965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraper for arxiv physics\n",
    "scraper = ax.Scraper(category='physics', date_from='2020-01-01',\n",
    "                     date_until='2022-08-03', t=10,\n",
    "                     filters={'categories':['quant-ph']})\n",
    "\n",
    "output = scraper.scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df391a-9a31-41a6-b51c-c7394fb64c55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e123b7-e935-4b7e-a299-0dba16f500f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the results into a DataFrame to see what they look like, then save them to a csv for future use\n",
    "cols = ('id', 'title', 'categories', 'abstract', 'doi', 'created', 'updated', 'authors')\n",
    "df = pd.DataFrame(output,columns=cols)\n",
    "df.to_csv('Data/Scraped_physics_outputs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74376c4-1bb6-4339-9e05-b2fb18ddc64e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract title data and export to csv file\n",
    "titles = df.title.tolist()\n",
    "display(titles[:5])\n",
    "\n",
    "np.savetxt('Data/Scraped_physics_titles.csv', np.array(titles), header='Titles',comments=\"\", fmt='%s', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0050f4-b791-477a-b8c1-e758ba5f9220",
   "metadata": {},
   "source": [
    "# 3. GPT-2 FineTuning on Title Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd44a26-dd4e-4030-b107-ac6735f9a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"117M\" # \"355M\" = Larger model (1.4 GB)\n",
    "gpt2.download_gpt2(model_name=model_name)   # Saved into current directory under /models/117M/\n",
    "\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.finetune(sess,\n",
    "              'Data/Scraped_physics_titles.csv',\n",
    "              model_name=model_name,\n",
    "              steps=1000,\n",
    "              save_every=200,\n",
    "              sample_every=25)\n",
    "\n",
    "gpt2.generate(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cfb234-ab54-4b0c-9fe7-88e8d1c7378e",
   "metadata": {},
   "source": [
    "# 4. Examine Sample Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb3d5c-ad0c-483f-9ce0-f13a0a198e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = 'samples/run1/samples-76'\n",
    "sample_file = open(sample_file, 'r').read()\n",
    "\n",
    "for s in ['endoftext', 'startoftext', '<|', '|>']:\n",
    "    t = t.replace(s, '')\n",
    "for title in t.title().split('\\n')[1:]:\n",
    "    if not title == '':\n",
    "        print('- ' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a0e03-86d7-40e6-949e-7e3f730705dd",
   "metadata": {},
   "source": [
    "# 5. Generate New Sample Titles\n",
    "\n",
    "- Kernel Restart Required AFTER fine-tuning.\n",
    "- This restriction is specifically caused by the GPT-2 Module - See [Github Thread](https://github.com/minimaxir/gpt-2-simple/issues/80) for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb477b5-da73-4a11-ac21-46c4fd87a224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint\\run1\\model-100\n",
      "INFO:tensorflow:Restoring parameters from checkpoint\\run1\\model-100\n"
     ]
    }
   ],
   "source": [
    "# Restart Kernel and execute if fresh, else ignore\n",
    "import gpt_2_simple as gpt2\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f1163c6-5eac-48bf-ad50-519ee63c5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_titles(n):\n",
    "    \n",
    "    text = gpt2.generate(sess,\n",
    "                         length=40,\n",
    "                         temperature=0.4,\n",
    "                         nsamples=n,\n",
    "                         batch_size=1,\n",
    "                         return_as_list=True\n",
    "                         )\n",
    "    titles_lst = []\n",
    "    for title in text:\n",
    "        t = title.title()\n",
    "        # remove extraneous text from GPT-2 Output\n",
    "        t = t.replace('<|Startoftext|>','').replace('\\n','').replace('| Startoftext|','')\n",
    "        # only grab a single title\n",
    "        t = t[:t.index('<|Endoftext|>')]\n",
    "        if t == '':\n",
    "            continue\n",
    "        else:\n",
    "            print(t)\n",
    "            titles_lst.append(t)\n",
    "    return titles_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ec56d-cd3b-4a87-95d9-1128d799ae1d",
   "metadata": {},
   "source": [
    "#### Single Sample Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "441e067c-3008-45c3-9792-7339b5096959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum And Classical Information Theory: A Unified Theory Of The Quantum   Phase Transition\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Quantum And Classical Information Theory: A Unified Theory Of The Quantum   Phase Transition']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample_titles(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9741552c-5143-4609-bda0-1634f7c8b79d",
   "metadata": {},
   "source": [
    "#### Multiple Sample Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd1cbfc6-e906-4629-a657-0d5b9d658961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilistic Simulation Of Quantum Mechanics\n",
      "A New Way Of Estimating The Entropy Of Quantum Systems\n",
      "Quantum And Classical Information Processing In Quantum Mechanics\n",
      "|Startoftext|>Quantum Key Distribution With A Quantum Processor\n",
      "A Quantum Walker For The Quantum Computer\n",
      "Theory Of Quantum Mechanics And The Quantum Contextuality\n",
      ">Quantum Information Retrieval With A Quantum Processor\n",
      "A New Approach To Quantum Estimation\n",
      "Quantum Key Distribution With An Atomic Engine\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Probabilistic Simulation Of Quantum Mechanics',\n",
       " 'A New Way Of Estimating The Entropy Of Quantum Systems',\n",
       " 'Quantum And Classical Information Processing In Quantum Mechanics',\n",
       " '|Startoftext|>Quantum Key Distribution With A Quantum Processor',\n",
       " 'A Quantum Walker For The Quantum Computer',\n",
       " 'Theory Of Quantum Mechanics And The Quantum Contextuality',\n",
       " '>Quantum Information Retrieval With A Quantum Processor',\n",
       " 'A New Approach To Quantum Estimation',\n",
       " 'Quantum Key Distribution With An Atomic Engine']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample_titles(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da82097a-380b-4b81-b91b-779b400bc95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT2_Env",
   "language": "python",
   "name": "gpt2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
